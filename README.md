# EEG/MEG self-supervised representation learning with JEPA

Cross-dataset transfer learning presents a lot of challenges in EEG/MEG signal processing, specifically for MEG since it's a much more expensive technique with less data available. Recent approaches to learn useful representations from large EEG datasets utilize contrastive learning, however, these frameworks are highly sensitive to individual variance in the datasets used for pre-training, and the introduction of data augmentations introduce a lot of bias which may decrease downstream task performance.

Could a Joint-Embedding Predictive Architecture enhance transfer learning capabilities on EEG/MEG datasets?


## Reading material

- [ ] Self-Supervised Pre-Training with Joint-Embedding Predictive Architecture Boosts ECG Classification Performance, [arXiv link](https://arxiv.org/abs/2410.13867).
- [ ] Enhancing JEPAs with Spatial Conditioning: Robust and Efficient Representation Learning, [arXiv link](https://arxiv.org/abs/2410.10773).
- [ ] Learning General Representation of 12-Lead Electrocardiogram with a Joint-Embedding Predictive architecture, [arXiv link](https://arxiv.org/abs/2410.08559).
- [ ] T-JEPA: Augmentation-Free Self-Supervised Learning for Tabular Data, [arXiv link](https://arxiv.org/abs/2410.05016).
- [ ] Brain-JEPA: Brain Dynamics Foundation Model with Gradient Positioning and Spatiotemporal Masking, [arXiv link](https://arxiv.org/abs/2409.19407).
- [ ] 3D-JEPA: A Joint Embedding Predictive Architecture for 3D Self-Supervised Representation Learning, [arXiv link](https://arxiv.org/abs/2409.15803).
- [ ] Learning Latent Wireless Dynamics from Channel State Information, [arXiv link](https://arxiv.org/abs/2409.10045).
- [ ] Stem-JEPA: A Joint-Embedding Predictive Architecture for Musical Stem Compatibility Estimation, [arXiv link](https://arxiv.org/abs/2408.02514).
- [ ] Masked Modeling Duo: Learning Representations by Encouraging Both Networks to Model the Input, [arXiv link](https://arxiv.org/abs/2210.14648).
- [ ] Supervised and Unsupervised Learning of Audio Representations for Music Understanding, [arXiv link](https://arxiv.org/abs/2210.03799).
- [ ] Contrastive Learning of General-Purpose Audio Representations, [IEEE link](https://ieeexplore.ieee.org/document/9413528).
- [ ] Contrastive Learning of Musical Representations, [arXiv link](https://arxiv.org/abs/2103.09410).
- [ ] Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere, [MLR link](https://proceedings.mlr.press/v119/wang20k/wang20k.pdf).
- [ ] wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations, [NIPS link](https://proceedings.neurips.cc/paper/2020/file/92d1e1eb1cd6f9fba3227870bb6d7f07-Paper.pdf).
- [ ] W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training, [IEEE link](https://ieeexplore.ieee.org/document/9688253).
- [ ] A-JEPA: Joint-Embedding Predictive Architecture Can Listen, [arXiv link](https://arxiv.org/abs/2311.15830).
- [ ] S-JEPA: towards seamless cross-dataset transfer through dynamic spatial attention, [arXiv link](https://arxiv.org/abs/2403.11772).
- [ ] Cross-dataset transfer learning for motor imagery signal classification via multi-task learning and pre-training , [PubMed link](https://pubmed.ncbi.nlm.nih.gov/37774694/).
- [ ] T-JEPA: A Joint-Embedding Predictive Architecture for Trajectory Similarity Computation, [arXiv link](https://arxiv.org/abs/2406.12913).
- [ ] How JEPA Avoids Noisy Features: The Implicit Bias of Deep Linear Self Distillation Networks, [arXiv link](https://arxiv.org/abs/2407.03475).
- [ ] You Don't Need Data-Augmentation in Self-Supervised Learning, [arXiv link](https://arxiv.org/abs/2406.09294).
- [ ] Time-Series JEPA for Predictive Remote Control under Capacity-Limited Networks, [arXiv link](https://arxiv.org/abs/2406.04853).
- [ ] LaT-PFN: A Joint Embedding Predictive Architecture for In-context Time-series Forecasting, [arXiv link](https://arxiv.org/abs/2405.10093).
- [ ] Investigating Design Choices in Joint-Embedding Predictive Architectures for General Audio Representation Learning, [arXiv link](https://arxiv.org/abs/2405.08679).
- [ ] The relationship between MEG and fMRI , [PubMed link](https://pubmed.ncbi.nlm.nih.gov/24239589/).
- [ ] Joint-Embedding Masked Autoencoder for Self-supervised Learning of Dynamic Functional Connectivity from the Human Brain, [arXiv link](https://arxiv.org/abs/2403.06432).
- [ ] A-JEPA: Joint-Embedding Predictive Architecture Can Listen, [arXiv link](https://arxiv.org/abs/2311.15830).
- [ ] Joint Embedding Predictive Architectures Focus on Slow Features, [arXiv link](https://arxiv.org/abs/2211.10831).
